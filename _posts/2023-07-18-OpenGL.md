---
layout: post
title: OpenGL Scene
---
## Introduction
Today I will talk about the openGL scene I have made for the GPR5300 course at SAE Institute Geneva. 
The scene implements the techniques as detailed on the website LearnOpenGL.com.

The end result is this little planet : 
![](/images/PlanetCapture.PNG)<br/>

Throughout this article, I will provide an overview of the concepts employed, showcasing the workings of model loading, CubeMaps, PBR (Physically Based Rendering), instancing, point lights with shadow maps, as well as HDR (High Dynamic Range) and physically-based bloom effects.
Model Loading: One of the fundamental aspects of creating a compelling scene is the ability to load and render complex 3D models. By utilizing the Assimp library, I was able to import models in various formats such as obj, fbx etc…

## CubeMaps and Skybox:
The first element that is going to be drawn into the screen will be the skybox. In our case that will be outer space with a big planet above us. 
IMAGES
A cubemap is simply six images sewn together so we take those six and apply them to a cube that will stay centered on our camera. This creates the effect where we can look around to see different part of the skybox but if we were to move around the skybox doesn’t appear to move. To enable this, we disable depth writing while we draw the skybox so that It can be later drawn over by other objects in the scene (as few objects would otherwise be closer to us since the skybox is really just a cube of unit length).
## PBR (Physically Based Rendering): 
Physically Based Rendering is an advanced technique that strives to simulate the behavior of light in a physically accurate manner. It works by giving approximation of the behavior of a light ray’s interaction with the physical surface of the object which is why we can now utilize height and normal maps to fake depth and irregularities into an otherwise flat surface. The PBR reflection model isn’t the only one but I chose over the Blinn-Phong reflection model because the former yields more realistic results for similar conditions.
## Instancing:
Drawing a lot of object requires a lot of draw calls. And making a lot of draw calls means we have to wait a lot on the communication between the graphics card and the CPU. But, there is another way. With instancing, we can group up items that use the same model with an instanced draw call. To do this, we only have to give openGL the complete array of model matrices of our objects in the form of a Vertex Buffer attached to its Vertex Array.
Show code
And then we draw we can simply update the Vertex buffer:
Show code
## Point Lights and Shadow Maps:
Lighting plays a crucial role in creating a realistic and immersive scene. To achieve this, I incorporated point lights into my OpenGL project. Point lights emit light in all directions. To make lighting work with our PBR, it’s a simple as informing every object’s shader of the lights’ positions and colors. Additionally, I implemented shadow mapping techniques to cast shadows accurately from these point lights, adding depth and realism to the scene. Shadow mapping for point lights is slightly different as for directional lights because a point light might potentially cast shadows in all directions. Normally for a directional light’s shadow mapping we would draw the scene once but only recording the depth to a texture and then use that texture with a light space matrix to tell what areas are in shadow or not. For point lights we do the same but we record the depth data not in a simple texture but a cubemap so that we can have omnidirectional information about the depth of the scene from the light’s point of view. The technique however, has an heavy performance cost: For each shadow-casting light in our scene we must render the relevant object one additional time. While we don’t have to deal with the object’s texture by using a simplified shader for these depth pass, the cost is still quite great which is why we rarely see games use a plethora of shadow-casting lights at the same time. Unless they are pre-calculated in which case the burden is non-existent. I couldn’t use this technique of baking however as I wanted to have a rotating planet which meant dynamically changing shadows.
## HDR and Physically-Based Bloom:
High dynamic range (HDR) imaging was used to play with a higher range of color while still being able to display them. Without going into too much details, HDR was used for the PBR shader. But mostly, what HDR allows is to do bloom effects:
Bloom works by taking an image with only the bright parts of the render and downSampling it to a lower resolution image over and over and then upSampling it to the original resolution. This allows for the bright pixels to bleed over to their neighbors. This particular bloom effect isn’t the one found in the lessons of LearnOpenGL but a more realistic physically based version whose details can be found in the guest articles of the website: LINK
# Conclusion:
In this blog post, I've discussed the OpenGL scene I created for the GPR5300 course at SAE Institute Geneva. By incorporating techniques such as model loading, CubeMaps and skybox, PBR, instancing, point lights with shadow maps, and HDR with physically-based bloom effects, I was able to create a small planet environment. Through this project, I gained a deeper understanding of graphics programming and the power of OpenGL to create captivating visual environments.
